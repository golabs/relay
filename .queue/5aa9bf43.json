{"id": "5aa9bf43", "message": "below is a markdown file that I'd you to add to Skynet call it skynet_cdc.md\n\nI also you to review the file and action it as well please \n\n# Skynet: InsuredHQ Persistence Layer for CDC Integration\n\n## Context\n\nARTEMIS is building a centralised datalake that uses **Change Data Capture (CDC)** via Debezium to automatically sync data from each app's PostgreSQL database. Debezium reads PostgreSQL's Write-Ahead Log (WAL) and streams every INSERT/UPDATE/DELETE to Azure Event Hubs, which then flows into the datalake.\n\nFor **inbound InsuredHQ sync** (InsuredHQ \u2192 datalake), the architecture relies on Skynet writing InsuredHQ data to its own PostgreSQL so Debezium can capture it. **Skynet currently does not do this** \u2014 it's a pass-through proxy that queries InsuredHQ on-the-fly and returns results without persisting them locally.\n\n## What Needs to Change\n\nSkynet needs **6 new PostgreSQL tables** to persist InsuredHQ business data. The Pydantic models already exist in `app/integrations/insuredhq/types.py` \u2014 you need corresponding SQLAlchemy models and a write-through pattern.\n\n## New Tables\n\n| Table | Source Pydantic Model | Purpose |\n|-------|----------------------|---------|\n| `skynet_ihq_policies` | `InsuredHQPolicy` | Policies fetched from InsuredHQ |\n| `skynet_ihq_claims` | `InsuredHQClaim` | Claims fetched from InsuredHQ |\n| `skynet_ihq_insureds` | `InsuredHQInsured` | Insured/client records from InsuredHQ |\n| `skynet_ihq_documents` | `InsuredHQDocument` | Document metadata from InsuredHQ |\n| `skynet_ihq_invoices` | `InsuredHQInvoice` | Invoices from InsuredHQ |\n| `skynet_ihq_payments` | `InsuredHQPayment` | Payments from InsuredHQ |\n\n## Schema: `skynet_ihq_policies`\n\nBased on `InsuredHQPolicy` in `types.py`:\n\n```sql\nCREATE TABLE skynet_ihq_policies (\n    pk                  BIGSERIAL PRIMARY KEY,\n    ihq_id              VARCHAR(255) NOT NULL UNIQUE,   -- InsuredHQ's internal ID\n    policy_number       VARCHAR(255),\n    insured_name        VARCHAR(255),\n    policy_type         VARCHAR(100),\n    effective_date      DATE,\n    expiration_date     DATE,\n    coverage_limit      DOUBLE PRECISION,\n    deductible          DOUBLE PRECISION,\n    premium             DOUBLE PRECISION,\n    status              VARCHAR(50),\n    ihq_created_at      TIMESTAMP,                      -- InsuredHQ's timestamp\n    ihq_updated_at      TIMESTAMP,                      -- InsuredHQ's timestamp\n    fetched_at          TIMESTAMP NOT NULL DEFAULT NOW(),-- when Skynet fetched it\n    updated_at          TIMESTAMP NOT NULL DEFAULT NOW() -- local update timestamp\n);\n```\n\n## Schema: `skynet_ihq_claims`\n\nBased on `InsuredHQClaim` in `types.py`:\n\n```sql\nCREATE TABLE skynet_ihq_claims (\n    pk                  BIGSERIAL PRIMARY KEY,\n    ihq_id              VARCHAR(255) NOT NULL UNIQUE,\n    claim_number        VARCHAR(255),\n    insured_name        VARCHAR(255),\n    policy_number       VARCHAR(255),\n    policy_type         VARCHAR(100),\n    loss_date           DATE,\n    reported_date       DATE,\n    claim_type          VARCHAR(100),\n    status              VARCHAR(50),                    -- Open/Pending/Approved/Declined/Closed\n    claim_amount        DOUBLE PRECISION,\n    reserve_amount      DOUBLE PRECISION,\n    paid_amount         DOUBLE PRECISION,\n    handler             VARCHAR(255),\n    description         TEXT,\n    ihq_created_at      TIMESTAMP,\n    ihq_updated_at      TIMESTAMP,\n    fetched_at          TIMESTAMP NOT NULL DEFAULT NOW(),\n    updated_at          TIMESTAMP NOT NULL DEFAULT NOW()\n);\n```\n\n## Schema: `skynet_ihq_insureds`\n\nBased on `InsuredHQInsured` in `types.py`:\n\n```sql\nCREATE TABLE skynet_ihq_insureds (\n    pk                  BIGSERIAL PRIMARY KEY,\n    ihq_id              VARCHAR(255) NOT NULL UNIQUE,\n    name                VARCHAR(255),\n    email               VARCHAR(255),\n    phone               VARCHAR(100),\n    address             JSONB,                          -- {street, city, state, postcode, country}\n    type                VARCHAR(50),                    -- 'individual' / 'business'\n    ihq_created_at      TIMESTAMP,\n    ihq_updated_at      TIMESTAMP,\n    fetched_at          TIMESTAMP NOT NULL DEFAULT NOW(),\n    updated_at          TIMESTAMP NOT NULL DEFAULT NOW()\n);\n```\n\n## Schema: `skynet_ihq_documents`\n\n```sql\nCREATE TABLE skynet_ihq_documents (\n    pk                  BIGSERIAL PRIMARY KEY,\n    ihq_id              VARCHAR(255) NOT NULL UNIQUE,\n    filename            VARCHAR(500),\n    content_type        VARCHAR(100),\n    size                BIGINT,\n    claim_id            VARCHAR(255),                   -- FK to skynet_ihq_claims.ihq_id\n    policy_id           VARCHAR(255),                   -- FK to skynet_ihq_policies.ihq_id\n    uploaded_at         TIMESTAMP,\n    fetched_at          TIMESTAMP NOT NULL DEFAULT NOW()\n);\n```\n\n## Schema: `skynet_ihq_invoices`\n\n```sql\nCREATE TABLE skynet_ihq_invoices (\n    pk                  BIGSERIAL PRIMARY KEY,\n    ihq_id              VARCHAR(255) NOT NULL UNIQUE,\n    invoice_number      VARCHAR(255),\n    client_name         VARCHAR(255),\n    amount              DOUBLE PRECISION,\n    due_date            DATE,\n    status              VARCHAR(50),\n    ihq_created_at      TIMESTAMP,\n    fetched_at          TIMESTAMP NOT NULL DEFAULT NOW(),\n    updated_at          TIMESTAMP NOT NULL DEFAULT NOW()\n);\n```\n\n## Schema: `skynet_ihq_payments`\n\n```sql\nCREATE TABLE skynet_ihq_payments (\n    pk                  BIGSERIAL PRIMARY KEY,\n    ihq_id              VARCHAR(255) NOT NULL UNIQUE,\n    payment_number      VARCHAR(255),\n    amount              DOUBLE PRECISION,\n    payment_date        DATE,\n    status              VARCHAR(50),\n    type                VARCHAR(50),                    -- 'client' / 'creditor'\n    fetched_at          TIMESTAMP NOT NULL DEFAULT NOW()\n);\n```\n\n## Code Changes Required\n\n### 1. Add SQLAlchemy models (`app/db/models.py` or new file `app/db/ihq_models.py`)\n\nCreate SQLAlchemy models matching the tables above. Mirror the field names from the existing Pydantic models in `types.py`.\n\n### 2. Add write-through to the InsuredHQ client (`app/integrations/insuredhq/client.py`)\n\nCurrently the client fetches from InsuredHQ and returns Pydantic objects directly. Change this to **upsert** (INSERT ON CONFLICT UPDATE) the response data into the corresponding `skynet_ihq_*` table before returning. The upsert key is `ihq_id` (InsuredHQ's internal ID).\n\nPseudocode for the pattern:\n\n```python\nasync def get_policies(self, ...):\n    # Existing: fetch from InsuredHQ API\n    response = await self._query(\"policy_transaction\", ...)\n    policies = [InsuredHQPolicy(**item) for item in response]\n\n    # NEW: persist to local PostgreSQL\n    await self._upsert_ihq_records(\"skynet_ihq_policies\", policies)\n\n    return policies\n```\n\nApply this to all entity fetch methods: policies, claims, insureds, documents, invoices, payments.\n\n### 3. Add a polling/sync job (new file, e.g. `app/jobs/ihq_sync.py`)\n\nA scheduled task that periodically fetches recently modified records from InsuredHQ and upserts them locally. This catches changes made directly in InsuredHQ (manual entries, third-party integrations) that wouldn't be triggered by an ARTEMIS app.\n\n- Call InsuredHQ with a `modified_since` filter (last poll timestamp)\n- Upsert results into `skynet_ihq_*` tables\n- Store last poll timestamp (per entity type) in a `skynet_ihq_sync_state` table\n- Suggested interval: every 5 minutes (configurable)\n\n### 4. PostgreSQL config\n\nEnsure `wal_level=logical` is set on Skynet's PostgreSQL (required for Debezium to read the WAL). This is a one-time config change \u2014 no code needed but the DB may need a restart.\n\n## What NOT to Change\n\n- **Existing API endpoints** \u2014 `/api/insuredhq/claims`, `/api/insuredhq/policies`, etc. should continue working exactly as they do now. The persistence is additive.\n- **Existing models** \u2014 `User`, `Session`, `APIKey`, `APIConnection`, `AggregatedMetrics`, `AuditLog` are unchanged.\n- **Pydantic models** \u2014 `types.py` is unchanged. The SQLAlchemy models are new and separate.\n- **Outbound sync** \u2014 Skynet doesn't need to handle outbound (datalake \u2192 InsuredHQ) yet. That will be triggered by the datalake transformer calling Skynet's existing POST endpoints. The current API surface is sufficient.\n\n## Why This Matters\n\nWithout these tables, Debezium has nothing to capture from Skynet's WAL for InsuredHQ data. The entire inbound sync path (InsuredHQ \u2192 datalake) depends on Skynet persisting the data locally first. This is a **prerequisite for Phase 5** of the datalake rollout.\n\n## Migration\n\nAdd an Alembic migration (or equivalent) to create all 6 tables + the `skynet_ihq_sync_state` table. The tables should be created empty \u2014 the polling job will populate them on first run.\n\n---\n[AGENT MODE: Architect] Use the Task tool with subagent_type=\"Plan\" for architecture decisions. Focus on system design and integration points.\n\n/orchestrate", "model": "sonnet", "project": "skynet", "images": [], "status": "completed", "created": 1770963378.2473788, "personality": "neutral", "activity": "6 agents working: Create background sync worker", "started_at": 1770963378.4756405}