# Simple Explanation: WALTER Azure Integration — Mobile Voice App

## 1. What This File Does

This document is a technical blueprint explaining how to connect a mobile phone app (Walter Voice) to an existing AI assistant system (Walter) that already runs on Microsoft's cloud servers (Azure). Think of it like an instruction manual for building a remote control (the mobile app) that connects to a smart home system (Walter backend) that's already installed and working. The document explains how users will log in securely using their Microsoft work accounts, how voice conversations will flow between the phone and the AI, and what technical pieces the mobile developer needs to build to make it all work together.

---

## 2. Key Components

### **A. The Big Picture (Section 1)**
A visual diagram showing the complete system architecture:
- **Mobile App Layer**: The phone interface with login, voice mode, and quote display screens
- **Connection Layer**: The secure communication bridge (HTTPS for web requests, WSS for live voice streaming)
- **Azure Backend Layer**: Microsoft's cloud servers running Walter's brain, including:
  - **Express API**: Handles login, data requests, and business logic
  - **Voice Proxy**: Routes live voice conversations to the AI
  - **HAL Pricing Engine**: Calculates insurance quotes
  - **PostgreSQL Database**: Stores user accounts and quotes
  - **Azure OpenAI Realtime API**: The actual AI that understands speech and responds
  - **Redis Cache**: Temporary storage for active user sessions
  - **Microsoft Entra ID**: The security gatekeeper that controls who can access what

**Key Insight**: The mobile app doesn't contain Walter—it's just a window into the existing Walter system. All the AI intelligence, data, and business logic already exist on Azure servers.

### **B. Microsoft Entra ID — The Gatekeeper (Section 2)**
Explanation of the security and access control system:

**What Entra ID Controls:**
1. **Who can use the app**: Only employees added to the company's Microsoft system
2. **What company they belong to**: Ensures people from Company A can't see Company B's data
3. **What role they have**: Broker (full access), Admin (management access), or Viewer (read-only)
4. **Session validity**: Whether someone's login is still active or has expired

**Mobile Login Process (8 Steps):**
1. User taps "Sign in with Microsoft"
2. Phone opens Microsoft's official login page in a browser
3. User enters password (possibly with fingerprint/face ID for extra security)
4. Microsoft sends back a temporary authorization code
5. App sends that code to Walter's servers
6. Walter's servers exchange the code with Microsoft for identity verification (using a secret the app never sees)
7. Walter creates its own security passes (JWT tokens) and sends them to the phone
8. Phone stores these passes in the most secure storage available (iOS Keychain or Android Keystore)

**Security Configuration Needed:**
- Register the mobile app with Microsoft's system
- Set the redirect address: `msauth.com.walter.voice://auth` (where Microsoft sends users back after login)
- Enable "public client" mode (allows mobile apps to log in without storing secret passwords)

**Role-Based Access Table:**
| Role | What They Can Do | What Walter Shows Them |
|------|------------------|------------------------|
| Broker | Full access to their clients' quotes and policies | Can generate quotes and compare insurers |
| Admin | Company-wide data and user management | Same as Broker plus admin functions |
| Viewer | Read-only access to assigned quotes | Can ask questions but can't create new quotes |

### **C. Voice Pipeline — How Audio Flows (Section 3)**
Technical details about how voice conversations work:

**Connection Sequence (12 Steps):**
Think of this like making a phone call:
1. **Request a line**: App asks Walter's servers for permission to start a voice session
2. **Get connection details**: Walter responds with a special URL and session ticket
3. **Open the voice channel**: App establishes a live two-way connection (WebSocket)
4. **Walter connects to the AI**: Backend server connects to Azure OpenAI's voice system
5. **Start talking**: App streams microphone audio to Walter
6. **Walter forwards it**: Backend sends audio to the AI
7. **AI processes speech**: The AI understands what was said and may trigger actions (like looking up insurance quotes from the HAL pricing engine)
8. **AI responds with voice**: Azure OpenAI sends back spoken audio
9. **Text transcript arrives**: A written version of what the AI said
10. **Data arrives**: If the AI looked up a quote, the quote details are sent
11. **Display the quote**: App shows the insurance quote on screen
12. **Play the audio**: App plays the AI's voice response through the phone's speaker

**Audio Technical Specifications:**
| Setting | Value | What It Means |
|---------|-------|---------------|
| Format | PCM16 | Uncompressed, high-quality audio |
| Sample rate | 24,000 Hz | 24,000 audio measurements per second |
| Channels | 1 (mono) | Single audio channel |
| Bit depth | 16-bit | Quality level (CD quality is also 16-bit) |
| Data usage | ~48 KB/s | About 14 MB for a 5-minute call |
| Chunk size | 200ms | Audio is sent in small 200-millisecond pieces |

**Message Types Exchanged:**
The app and server send different types of messages:
- **Audio chunks**: Sound data encoded as text (base64)
- **Control messages**: Start session, end session, mute
- **Transcripts**: Written text of what was spoken (both user and AI)
- **Quote data**: Insurance quote details from the AI's database searches
- **Session events**: Connection ready, session expired, errors

**Development vs. Production:**
- **Development mode**: App connects directly to the backend server for testing
- **Production mode**: Uses Azure Web PubSub (a specialized message routing service) for scalability and reliability across global users

### **D. What the Mobile App Needs to Build (Section 4)**
A breakdown of the code architecture the mobile developer must create:

**Four Core Services:**
1. **Auth Service**: Handles Microsoft login, token storage, and automatic token renewal
2. **API Client**: Makes authenticated web requests to Walter's backend with automatic retry if tokens expire
3. **Voice Service**: Manages the WebSocket connection and session lifecycle
4. **Quote Service**: Handles insurance quote data received from voice conversations

**Additional Components:**
- **Audio Capture**: Records from microphone and converts to PCM16 format
- **Audio Playback**: Converts received audio back to sound through the speaker
- **Auth Context**: Shares login status across all screens in the app
- **Voice Context**: Shares voice session status across screens

**Environment Configuration:**
A settings file containing public information (NOT secrets):
- **API addresses**: Where to find Walter's servers (different for development vs. production)
- **Microsoft login settings**: Client ID, redirect address, permissions needed
- **Audio settings**: Sample rate (24,000 Hz), channels (1), chunk size (200ms)
- **Session timeouts**: How long before requiring re-login (30 minutes)
- **Token refresh timing**: When to get a fresh security token (5 minutes before expiry)

---

## 3. How It Works

### **The Complete User Journey:**

**Phase 1: Secure Entry (Login)**
Imagine entering a high-security corporate headquarters:

1. You arrive at the lobby and show your company employee badge (Microsoft account)
2. The security guard calls the Walter department to verify you're authorized
3. Walter's office checks with Microsoft to confirm your identity and permissions
4. You're issued **two keycards**:
   - **Access keycard** (JWT access token): Valid for 24 hours
   - **Renewal voucher** (JWT refresh token): Valid for 7 days, gets you new access keycards
5. These keycards are stored in a biometric safe in your pocket (encrypted phone storage)
6. The system notes your company affiliation and role (broker/admin/viewer)

**Phase 2: Voice Connection Setup**
Like making a secure video call:

1. You request a private conference line from Walter's receptionist (negotiate endpoint)
2. Walter sets up a secure audio channel and gives you the dial-in details (WebSocket URL)
3. You connect your phone to that channel
4. Walter simultaneously connects that channel to the AI system on the other end
5. Now you have a live two-way audio connection: You ↔ Walter Backend ↔ Azure OpenAI

**Phase 3: Live Conversation**
The actual voice interaction:

1. **You speak**: "I need home insurance for my property in Sydney"
2. **Your phone captures** the audio from your microphone
3. **Audio is encoded** into PCM16 format (like how CDs store music)
4. **Sent in chunks**: Audio streams to Walter in 200-millisecond pieces
5. **Walter forwards** it to Azure OpenAI's voice AI
6. **AI processes speech**: Understands your request and decides to search for insurance quotes
7. **AI calls HAL**: Triggers the pricing engine function to calculate quotes for Sydney properties
8. **Three responses come back simultaneously**:
   - **Voice audio**: "I can help you with that. I've found three quotes for your Sydney property..."
   - **Text transcript**: Written version of what the AI said
   - **Structured data**: Actual quote details (Allianz $2,847/year, QBE $3,120/year, Zurich $2,950/year)
9. **Your phone displays** the quote comparison on screen
10. **Your phone plays** the AI's voice through the speaker

**Phase 4: Data Security & Isolation**
Behind the scenes:

- Every request includes your access keycard (JWT token)
- Walter checks: Is this token valid? Has it expired?
- Walter enforces company isolation: You can only see your company's data
- Walter enforces role permissions: Viewers can't generate new quotes
- If your token is about to expire, the app automatically uses your renewal voucher to get a fresh one
- If the renewal voucher expires (after 7 days), you must log in again

---

## 4. Important Things to Know

### **This is Not a New System:**
The mobile app doesn't create a new version of Walter—it's a remote control for the existing system. All the AI intelligence, insurance pricing, customer data, and business logic already exist on Azure. The mobile app is just a portable interface to access it.

### **Security is Multi-Layered:**

1. **Microsoft Entra ID**: Controls who can even sign in (only company employees)
2. **PKCE Authentication**: Advanced login security that prevents hackers from stealing login codes
3. **Hardware-Encrypted Storage**: Security tokens stored in iOS Keychain or Android Keystore (chip-level encryption)
4. **Company Isolation**: Automatic data separation—Company A never sees Company B's quotes
5. **Role-Based Access**: Different employees see different features based on their job role
6. **Time-Limited Tokens**: Access passes expire regularly, requiring renewal or re-login

### **No Secrets in the App:**
The mobile app never contains or sees:
- Microsoft's client secret (only the backend server has this)
- Azure API keys
- Database passwords
- Any sensitive configuration

The app only stores the user-specific JWT tokens that Walter issues after verifying identity.

### **Voice is Live Streaming, Not Recording:**
Audio flows in real-time in 200-millisecond chunks. The app doesn't record entire conversations and upload them—it streams continuously like a phone call. This reduces latency (delay) and enables natural conversation flow.

### **Data Usage:**
A 5-minute voice call uses approximately 14 MB of data. This is reasonable for business use on WiFi or cellular data plans.

### **Development vs. Production Infrastructure:**
- **Development**: Direct WebSocket connections for faster testing
- **Production**: Azure Web PubSub acts as a global message router, handling connection management, automatic reconnection, and geographic distribution for users worldwide

### **Quote Data Flow:**
When the AI generates insurance quotes:
1. User asks for a quote via voice
2. AI triggers a function call to the HAL pricing engine
3. HAL calculates quotes from multiple insurers
4. Results flow back through the voice pipeline as structured data
5. Mobile app displays the quote comparison visually while the AI explains it verbally

### **Session Management:**
- **30-minute timeout**: If inactive for 30 minutes, the session expires
- **Auto-refresh**: The app automatically refreshes tokens 5 minutes before they expire
- **Graceful expiration**: If a session expires during a call, the user is notified and can reconnect

### **Azure Configuration Requirements:**
The existing Azure App Registration (which already handles desktop login) needs three additions:
1. Add "Mobile and desktop applications" as a platform
2. Add the mobile redirect URI: `msauth.com.walter.voice://auth`
3. Enable "Allow public client flows" setting

### **Role Examples:**
- **Sarah (Broker)**: Talks to Walter, generates quotes, compares insurers, sees her client portfolio
- **Mike (Admin)**: Does everything Sarah can do, plus manages user accounts and views company-wide analytics
- **Jessica (Viewer)**: Can ask Walter questions about assigned quotes but cannot create new quotes

---

## In Summary

This is an **integration specification** (not a standalone system design) that shows how to build a mobile front-end for an existing, fully-functional AI voice assistant backend. The document provides:

- **Complete security architecture** using Microsoft enterprise identity
- **Live voice streaming protocol** with detailed audio specifications
- **Step-by-step authentication flow** with PKCE security
- **WebSocket message catalog** for all communication types
- **Service architecture blueprint** for the mobile development team
- **Environment configuration** separating development and production
- **Data flow diagrams** showing how voice, quotes, and user data move through the system

It's like receiving architectural blueprints for adding a mobile remote control to an existing smart building system—the building (Walter on Azure) is already fully operational, and this document explains exactly how to build the remote control (mobile app) that connects to it securely and efficiently.